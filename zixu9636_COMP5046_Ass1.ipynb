{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zixu9636_COMP5046_Ass1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*"
      ]
    },
    {
      "metadata": {
        "id": "qTf21j_oQIiD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the user, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style*"
      ]
    },
    {
      "metadata": {
        "id": "iXbQohXLKSgO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1 - Data Preprocessing (Personality chat datasets)"
      ]
    },
    {
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1. Download Dataset (Personality chat datasets)"
      ]
    },
    {
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ca513f81-47c7-4997-b469-7658387cce94"
      },
      "cell_type": "code",
      "source": [
        "# downloading dataset from my own github\n",
        "!pip install -q xlrd\n",
        "!git clone https://github.com/zzeqii/ChatBotDataset.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ChatBotDataset'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)   \u001b[K\rremote: Counting objects:  11% (2/18)   \u001b[K\rremote: Counting objects:  16% (3/18)   \u001b[K\rremote: Counting objects:  22% (4/18)   \u001b[K\rremote: Counting objects:  27% (5/18)   \u001b[K\rremote: Counting objects:  33% (6/18)   \u001b[K\rremote: Counting objects:  38% (7/18)   \u001b[K\rremote: Counting objects:  44% (8/18)   \u001b[K\rremote: Counting objects:  50% (9/18)   \u001b[K\rremote: Counting objects:  55% (10/18)   \u001b[K\rremote: Counting objects:  61% (11/18)   \u001b[K\rremote: Counting objects:  66% (12/18)   \u001b[K\rremote: Counting objects:  72% (13/18)   \u001b[K\rremote: Counting objects:  77% (14/18)   \u001b[K\rremote: Counting objects:  83% (15/18)   \u001b[K\rremote: Counting objects:  88% (16/18)   \u001b[K\rremote: Counting objects:  94% (17/18)   \u001b[K\rremote: Counting objects: 100% (18/18)   \u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 2), reused 18 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JavPXPkQCDtx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c4dcf63-945d-4ce8-c98a-a019057495e4"
      },
      "cell_type": "code",
      "source": [
        "!ls ChatBotDataset\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "movie  personality\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2bH5Zq9u8S0X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#coverting tsv dataset to the dataframe\n",
        "import pandas as pd\n",
        "comicData=pd.read_csv('ChatBotDataset/personality/qna_chitchat_the_comic.tsv', sep='\\t')[['Question','Answer']].rename(columns={'Answer':'comic'})\n",
        "professionData=pd.read_csv('ChatBotDataset/personality/qna_chitchat_the_professional.tsv', sep='\\t')[['Question','Answer']].rename(columns={'Answer':'profession'})\n",
        "friendData=pd.read_csv('ChatBotDataset/personality/qna_chitchat_the_friend.tsv', sep='\\t')[['Question','Answer']].rename(columns={'Answer':'friend'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ehz5E9jj6Nxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c29b4f15-528b-4a8c-c6fc-9f6542b592ee"
      },
      "cell_type": "code",
      "source": [
        "comicData.head(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>comic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's your age?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you young?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When were you born?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Question          comic\n",
              "0     What's your age?  I'm age-free.\n",
              "1       Are you young?  I'm age-free.\n",
              "2  When were you born?  I'm age-free."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "DrhbobJREzXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b5ae0307-47e9-4fe1-cba2-e7923d3ff22d"
      },
      "cell_type": "code",
      "source": [
        "professionData.head(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>profession</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's your age?</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you young?</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When were you born?</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Question                       profession\n",
              "0     What's your age?  Age doesn't really apply to me.\n",
              "1       Are you young?  Age doesn't really apply to me.\n",
              "2  When were you born?  Age doesn't really apply to me."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "AZWWZl_EE56n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b643bc55-8b01-43d7-a92f-ed1089dbef6e"
      },
      "cell_type": "code",
      "source": [
        "friendData.head(3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>friend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's your age?</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you young?</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When were you born?</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Question                       friend\n",
              "0     What's your age?  I don't really have an age.\n",
              "1       Are you young?  I don't really have an age.\n",
              "2  When were you born?  I don't really have an age."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2. Preprocess data (Personality chat datasets)"
      ]
    },
    {
      "metadata": {
        "id": "8RdKI8E2KRwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The text preprocessing method are mainly used libries of spacy, gensim and nltk. The tequeniques consists of several steps,which will demonstrated as the pipeline shown below (same order for processing steps) \n",
        "\n",
        "1. **Normalization**\n",
        "Reomove the puctuation,number, whitespace from the sentence and lower all case for avoiding the noise.\n",
        "\n",
        "2.   **Word Tokenization **\n",
        "The sentence will be precessed as a sequence of tokenes for further preprocessing \n",
        "\n",
        "3.   **Part-of-speech**\n",
        "Part of Speech,is referring to category of words. Same category of words can represent similar behavior. For example, “Word” is a noun while “Run” is a verb. To have a better understanding on article, we have to know the POS. As lemmanization and stemming process relies on POS, in this task I use  library spaCy)to tacke it.\n",
        "\n",
        "4.  **Lemmanization**\n",
        "In English words (Other language as well), same word may have different form such as “affected”, “affects” and “affect”.To have a smaller size vocabulary and better representation on NLP problem, I want to have a single word to represent “”, “” in some scenarios.\n",
        "\n",
        "6. **Removing stop words**\n",
        "When we deal with text problem in Natural Language Processing, stop words removal process is a one of the important step to have a better input for any models. Stop words means that it is a very common words in a language (e.g. a, an, the in English). It does not help on most of NLP problem.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "emyl1lWxGr12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0badfa81-660e-4231-b02f-cf60ad46f122"
      },
      "cell_type": "code",
      "source": [
        "# creating the question and answer dictionary\n",
        "#all questions are same for all three dataset,\n",
        "#I merge three dataframes on question\n",
        "data=pd.merge(comicData.merge(professionData,on='Question'),friendData,on='Question')\n",
        "data.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>comic</th>\n",
              "      <th>profession</th>\n",
              "      <th>friend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What's your age?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you young?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When were you born?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What age are you?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Are you old?</td>\n",
              "      <td>I'm age-free.</td>\n",
              "      <td>Age doesn't really apply to me.</td>\n",
              "      <td>I don't really have an age.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Question          comic                       profession  \\\n",
              "0     What's your age?  I'm age-free.  Age doesn't really apply to me.   \n",
              "1       Are you young?  I'm age-free.  Age doesn't really apply to me.   \n",
              "2  When were you born?  I'm age-free.  Age doesn't really apply to me.   \n",
              "3    What age are you?  I'm age-free.  Age doesn't really apply to me.   \n",
              "4         Are you old?  I'm age-free.  Age doesn't really apply to me.   \n",
              "\n",
              "                        friend  \n",
              "0  I don't really have an age.  \n",
              "1  I don't really have an age.  \n",
              "2  I don't really have an age.  \n",
              "3  I don't really have an age.  \n",
              "4  I don't really have an age.  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Eb-tGzOvzZM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d09bf60-2285-4b9c-af65-7af8a3bd8325"
      },
      "cell_type": "code",
      "source": [
        "qu=data['Question']\n",
        "ac=data['comic']\n",
        "ap=data['profession']\n",
        "af=data['friend']\n",
        "allanw=data[['comic','profession','friend']]\n",
        "print(len(qu),len(ac),len(ap),len(af),len(allanw))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "687 687 687 687 687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fgH912oUT1bT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3d7fa95e-a3fe-42dc-c220-e875f2127b55"
      },
      "cell_type": "code",
      "source": [
        "#loading package for data preprocessing\n",
        "import spacy\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "import gensim\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.summarization.summarizer import summarize"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MaxinVkNXtWP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_words=stopwords.words('english')\n",
        "spacy_nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obE4gaYgzFVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "''' \n",
        "1.normalize sentence by using 're' library to remove puctuation,numbers,whitespace \n",
        "2.change all characcter to the lower case\n",
        "3.word tokenization and removing stop words by using spacy\n",
        "4.lemmatisation after removing stop words\n",
        "5.filtering words by the allowing POS\n",
        "\n",
        "'''\n",
        "\n",
        "def preprocess(que):\n",
        "  #allow_POS = [\"ADJ\",\"NOUN\",\"VERB\"]\n",
        "  token_sent=[]\n",
        "  for i in que:\n",
        "    txt=i.lower()\n",
        "    txt = re.sub(\"[\\!\\/_,%^*(+\\\"\\')]+|[+——()?【】'’“”！，。？、~@#￥%……&*（）]+\",\" \",i)\n",
        "    txt = re.sub(\"[\\s+]\",\" \",i)\n",
        "    txt=re.sub(r\"\\d+\", \" \",txt)\n",
        "    #word tikenisation\n",
        "    doc=spacy_nlp(txt)\n",
        "    #pipline storpwords and lemmatisation    \n",
        "    token_sent.append([tok.lemma_ for tok in doc \n",
        "                           if tok.lemma_ not in stop_words])\n",
        "  return token_sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1c7j6hXWFAKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "725a2323-a326-45cd-9db6-8d4735f0acb5"
      },
      "cell_type": "code",
      "source": [
        "qutoken=preprocess(qu)\n",
        "len(qutoken)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "ifuJd782A8bP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "2511943a-6275-4deb-905e-86bf7951c356"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "there is no need to tokenize question,\n",
        "as we are implementing the one-to-n model\n",
        "so the answer tokens are list of sentence\n",
        "'''\n",
        "anwtokenComic=list(set(data['comic']))\n",
        "anwtokenPro=list(set(data['profession']))\n",
        "anwtokenFre=list(set(data['friend']))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1a8a15ed5b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthe\u001b[0m \u001b[0manswer\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0manwtokenComic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0manwtokenPro\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'profession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0manwtokenFre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'friend'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LIu_lkJwQ55g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "metadata": {
        "id": "daDvAftceIvr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "lbzm-NWBTmM-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe which model was implemented (i.e. Word2Vec with CBOW, FastText with SkipGram, etc.) with justification of your decision *"
      ]
    },
    {
      "metadata": {
        "id": "3cM4rlYkHefJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "it6I1_K7HTub",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.1. Download Dataset for Word Embeddings\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4Op66omXKVHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe which data was used with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "QLjf_pm9NiA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f9dde1b9-445c-4b7d-d62b-eb86d3dbd78b"
      },
      "cell_type": "code",
      "source": [
        "# downlodaing the cornell movie training data.\n",
        "# The cornell movie dialog data has already been downloaded on the colab through the first step\n",
        "\n",
        "!ls ChatBotDataset/movie\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chameleons.pdf\t\t       movie_lines.txt\t\t  README.txt\n",
            "movie_characters_metadata.txt  movie_titles_metadata.txt\n",
            "movie_conversations.txt        raw_script_urls.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GXgFpxIgl-_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.2. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "qJrVHGYSmYMg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "3LByzHLiNinu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. Read from movie-lines.txt\n",
        "2. Creat a dictionary with (key=line_id,value=text)\n",
        "'''\n",
        "\n",
        "def get_id2line():\n",
        "  lines=open('ChatBotDataset/movie/movie_lines.txt',encoding='utf-8',errors=\"ignore\").read().split('\\n')\n",
        "  id2line={}\n",
        "  for line in lines:\n",
        "    line=line.split('+++$+++')\n",
        "    if len(line)==5:\n",
        "      '''In the movie_line.txt, elements in the line can be extracted \n",
        "      by spliting with +++$+++. The first item is the line id, the fourth \n",
        "      is the contains the actual text of each utterance'''\n",
        "      id2line[line[0].strip()]=line[4]\n",
        "  \n",
        "  return id2line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lq3HFBMkWWxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d479ab80-f0d2-4896-eda9-972c983fddfe"
      },
      "cell_type": "code",
      "source": [
        "uttrance=get_id2line()\n",
        "len(uttrance)\n",
        "uttrance['L194']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "6ZWAKFFLQuyn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "1. Read from movie-lines.txt\n",
        "2. Creat a list oflist of line_id's\n",
        "\n",
        "'''\n",
        "\n",
        "def get_conversations():\n",
        "  conv_lines=open('ChatBotDataset/movie/movie_conversations.txt',encoding='utf-8',errors=\"ignore\").read().split('\\n')\n",
        "  convs=[]\n",
        "  \n",
        "  '''\n",
        "  The last itme in the line is the list of the utterances that make the conversation, in chronological \n",
        "\t\t\torder: ['lineID1','lineID2',É,'lineIDN']\n",
        "\t\t\twhich is matched with movie_lines.txt to reconstruct the actual content\n",
        "  '''\n",
        "  \n",
        "  #processing without the last empty line\n",
        "  for line in conv_lines[:-1]:\n",
        "    #split line to pick the uttrance list \n",
        "    #select the list of utterance id without '[]'\n",
        "    #and replce special puctuation and whitespace\n",
        "    line=line.split('+++$+++')[-1].strip()[1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
        "    convs.append(line.split(','))\n",
        "    \n",
        "  return convs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFub6gEXXWpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c92b7d7b-9224-4b9f-d3b9-3f0bdfa57527"
      },
      "cell_type": "code",
      "source": [
        "lst_uttrance=get_conversations()\n",
        "len(lst_uttrance)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "QIbfAW64iU3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "755002fc-7f51-4f42-accb-bbcf931494bd"
      },
      "cell_type": "code",
      "source": [
        "lst_uttrance[:10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['L194', 'L195', 'L196', 'L197'],\n",
              " ['L198', 'L199'],\n",
              " ['L200', 'L201', 'L202', 'L203'],\n",
              " ['L204', 'L205', 'L206'],\n",
              " ['L207', 'L208'],\n",
              " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
              " ['L276', 'L277'],\n",
              " ['L280', 'L281'],\n",
              " ['L363', 'L364'],\n",
              " ['L365', 'L366']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "bYT9K8G0fL-Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Get lists of all conversations as Questions and Answers\n",
        "    1. [questions]\n",
        "    2. [answers]\n",
        "'''\n",
        "def gather_data(convs,id2line):\n",
        "  question=[]\n",
        "  answer=[]\n",
        "  \n",
        "  #extract question and answer\n",
        "  for conv in convs:\n",
        "\n",
        "#     if the conversation list has odd number items,\n",
        "#     it means that the conversiation ended up with the question but no answer.\n",
        "#     so I only select the q&a pair to process\n",
        "\n",
        "    for i in range(len(conv)-1):\n",
        "\n",
        "#        according to the movie_line.txt, id with odd number is answer,\n",
        "#        id with even numbser is question \n",
        "\n",
        "        question.append(id2line[conv[i]])\n",
        "        answer.append(id2line[conv[i+1]])\n",
        "   \n",
        "  return question,answer\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4NoBZS0xEPFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49f3773f-4dea-4699-d0e6-285a9d9a05d9"
      },
      "cell_type": "code",
      "source": [
        "questions,answers=gather_data(lst_uttrance,uttrance)\n",
        "print(len(questions),len(answers))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "221616 221616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wnZ5SbaHWWJi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "the following functions is to filter character\n",
        "to clean the vocabulary dictionary\n",
        "'''\n",
        "\n",
        "def clean_text(text):\n",
        "  #change all characters to lower case\n",
        "    text = text.lower()\n",
        "  #clean teh useless words,punctuations by using regular expression \n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    \n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CntbbTJvMLij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "899d1be3-d82c-42f4-bbd7-6d456dfddaf4"
      },
      "cell_type": "code",
      "source": [
        "clean_questions=[]\n",
        "for question in questions:\n",
        "  clean_questions.append(clean_text(question))\n",
        "len(clean_questions)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "IkMheBtwOZ6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe1243be-ea9b-4758-b051-0d2962859edc"
      },
      "cell_type": "code",
      "source": [
        "clean_answers=[]\n",
        "for answer in answers:\n",
        "  clean_answers.append(clean_text(answer))\n",
        "len(clean_answers)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "u27w-c06MLy4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# fiter too long and too short sequnence\n",
        "def filter_question(qu_lst,an_lst):\n",
        "  # here I set the min_length=2, max_length=20\n",
        "  min_len=2\n",
        "  max_len=20\n",
        "  # return the fitered question list and answer list\n",
        "  temp_que_lst=[]\n",
        "  temp_anw_lst=[]\n",
        "  i=0\n",
        "  for seq in qu_lst:\n",
        "    if len(seq.split())>=min_len and len(seq.split())<=max_len:\n",
        "      temp_que_lst.append(seq)\n",
        "      temp_anw_lst.append(an_lst[i])\n",
        "    i+=1\n",
        "  return temp_que_lst,temp_anw_lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n370n3srWQEc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def filter_answer(temp_qu_lst,temp_an_lst):\n",
        "  # here I set the min_length=2, max_length=20\n",
        "  min_len=2\n",
        "  max_len=20\n",
        "  # return the fitered question list and answer list\n",
        "  que_lst=[]\n",
        "  anw_lst=[]\n",
        "  i=0\n",
        "  for a in temp_an_lst:\n",
        "    if len(a.split())>=min_len and len(a.split())<=max_len:\n",
        "      anw_lst.append(a)\n",
        "      que_lst.append(temp_qu_lst[i])\n",
        "    i+=1\n",
        "  return que_lst,anw_lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSV1II2i_SsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''preprocessing data by pipelining the above functions'''\n",
        "\n",
        "def preprocess(q,a):\n",
        "  que_lst=[]\n",
        "  anw_lst=[]\n",
        "  for que in q:\n",
        "    que_lst.append(clean_text(que))\n",
        "  \n",
        "  for anw in a:\n",
        "    anw_lst.append(clean_text(anw))\n",
        "  \n",
        "  temp_que_lst,temp_anw_lst=filter_question(que_lst,anw_lst)\n",
        "  que_data,anw_data=filter_answer(temp_que_lst,temp_anw_lst)\n",
        "  return que_data,anw_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRAg_LsnJ_CV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bde30ec-cc38-482f-af8d-8dbbfc41a504"
      },
      "cell_type": "code",
      "source": [
        "queData,anwData=preprocess(questions,answers)\n",
        "print(len(queData),len(anwData))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138335 138335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSrraU0ZKSZP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create a dictionary for the frequency of the vocabulary \n",
        "in both question list and answer list\n",
        "'''\n",
        "\n",
        "def get_dict(qlst,alst):\n",
        "  vocab={}\n",
        "  for q in qlst:\n",
        "    for word in q.split():\n",
        "      if word not in vocab:\n",
        "        vocab[word]=1\n",
        "      else:\n",
        "        vocab[word]+=1\n",
        "  \n",
        "  for a in alst:\n",
        "    for wor in a.split():\n",
        "      if wor not in vocab:\n",
        "        vocab[wor]=1\n",
        "      else:\n",
        "        vocab[wor]+=1\n",
        "  return vocab\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqMZZzd3Ya5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d1709f7-a506-49fb-95d2-a31f2cd67103"
      },
      "cell_type": "code",
      "source": [
        "vocab=get_dict(queData,anwData)\n",
        "len(vocab)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "YDCqv0grYy1r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove rare words from the vocabulary.\n",
        "# I aim to replace fewer than 5% of words with <UNK> refereing to Unknown word\n",
        "# You will see this ratio soon.\n",
        "threshold = 10\n",
        "count = 0\n",
        "for k,v in vocab.items():\n",
        "    if v >= threshold:\n",
        "        count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OKyca_IMr9P7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "460d1269-cc8a-46b2-8393-6b9c3cc3fdca"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Size of total vocab:\", len(vocab))\n",
        "print(\"Size of vocab we will use:\", count)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of total vocab: 45618\n",
            "Size of vocab we will use: 8092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6yI0e5ydsQWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In case I want to use a different vocabulary sizes for the source and target text, \n",
        "# I can set different threshold values.\n",
        "# Nonetheless, I will create dictionaries to provide a unique integer for each word.\n",
        "questions_vocab_to_int = {}\n",
        "\n",
        "word_num = 0\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold:\n",
        "        questions_vocab_to_int[word] = word_num\n",
        "        word_num += 1\n",
        "        \n",
        "answers_vocab_to_int = {}\n",
        "\n",
        "word_num = 0\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold:\n",
        "        answers_vocab_to_int[word] = word_num\n",
        "        word_num += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-gwFULwr_GY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "6abc7ed3-75e8-4073-a03d-f112f0955153"
      },
      "cell_type": "code",
      "source": [
        "# Add the unique tokens to the vocabulary dictionaries.\n",
        "codes = ['<PAD>','<EOS>','<UNK>','<GO>']\n",
        "\n",
        "for code in codes:\n",
        "    questions_w2i[code] = len(questions_vocab_to_int)+1\n",
        "    \n",
        "for code in codes:\n",
        "    answers_w2i[code] = len(answers_vocab_to_int)+1"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-b57f1e591b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mquestions_w2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_vocab_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'questions_w2i' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tUHJASYYsg23",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create dictionaries to map the unique integers to their respective words.\n",
        "# i.e. an inverse dictionary for vocab_to_int.\n",
        "questions_i2w = {v_i: v for v, v_i in questions_vocab_to_int.items()}\n",
        "answers_i2w = {v_i: v for v, v_i in answers_vocab_to_int.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bZD2Z7JOsasg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ce074433-2af4-40ee-ef2a-3356db172c0f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the length of the dictionaries.\n",
        "print(len(questions_vocab_to_int))\n",
        "print(len(questions_int_to_vocab))\n",
        "print(len(answers_vocab_to_int))\n",
        "print(len(answers_int_to_vocab))\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8096\n",
            "8096\n",
            "8096\n",
            "8096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qhAgWf_AmbZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.3. Build Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "AJ8rU7JbiBVS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this taks, I will select to the skip-gram method to build up word2vector model and training with tersorflow\n"
      ]
    },
    {
      "metadata": {
        "id": "TVPuwWgvNjOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNys5HOdISK-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.4. Train Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "Ae8i7Z2kIef-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uMCv3YI1IfUo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.5. Save Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "3OwicNPkIqd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yn16xrDrIs8B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.6. Load Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "-IebpYFsIvgh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlCeWT8eeLnd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.2. Seq2Seq model"
      ]
    },
    {
      "metadata": {
        "id": "fwA-NN3EJ4Ig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.1. Apply/Import Word Embedding Model"
      ]
    },
    {
      "metadata": {
        "id": "UAMJrxx-iOVn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "g7PKX1gIePA2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DpYCL17JKZxl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.2. Build Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "R204UIyDKhZ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "13eCtR_SLUG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BaOiaGRLW7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.3. Train Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "lVQnUSX1LZ6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2feNpG-LZx2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.4. Save Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "sflUAgV4L1o8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4zFo6YppL6w3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.5. Load Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "OtNxLzDGMCan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a4mpRpocePLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3 - Evaluation (Running chatbot)"
      ]
    },
    {
      "metadata": {
        "id": "KEW1zMgVMREr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1. Start chatting"
      ]
    },
    {
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P28Z1k36MZuo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2. Change Personality"
      ]
    },
    {
      "metadata": {
        "id": "U8OBtJfvMgL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Explain how to change personality (What is the command for changing personality?). *"
      ]
    },
    {
      "metadata": {
        "id": "wTLyQEeZMZ2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y50Ep8KKMZ99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.3. Save chat log"
      ]
    },
    {
      "metadata": {
        "id": "bbZ6oOu6MaGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JISqR3jjMwwU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.4. End chatting"
      ]
    },
    {
      "metadata": {
        "id": "nT_DeoHSMw49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HpomO_3YNI5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.5. Execute program"
      ]
    },
    {
      "metadata": {
        "id": "cDkQJ9i_NH9D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Please make sure your program  is running properly.***\n",
        "\n",
        "***Functions for downloading (from Google Drive) and loading models (both word embeddings and Seq2Seq) need to be called!*** \n"
      ]
    },
    {
      "metadata": {
        "id": "_7J5hS_SOIUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.5.1. Execute program - training mode"
      ]
    },
    {
      "metadata": {
        "id": "_woLwuU3Mk3w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Please include lines to train the bot.*"
      ]
    },
    {
      "metadata": {
        "id": "xhWYz7NQOfLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65cZTuQ_OeI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.5.2. Execute program - chatting mode"
      ]
    },
    {
      "metadata": {
        "id": "D7LrbcP_PKap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Please include lines to start chatting with the bot.*"
      ]
    },
    {
      "metadata": {
        "id": "QVvzZsB7PbYf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfv8rWTKPzeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Object Oriented Programming codes here"
      ]
    },
    {
      "metadata": {
        "id": "TS23AjBRSZaX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*If you have multiple classes use multiple code snippets to add them.*"
      ]
    },
    {
      "metadata": {
        "id": "wSJJ4zRFQy1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If you used OOP style, use this sectioon"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}